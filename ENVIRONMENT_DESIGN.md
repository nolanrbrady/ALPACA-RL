## ALPACA Environment Design

### Purpose
Wrap the pretrained ALPACA dynamics model as a Gymnasium environment for reinforcement learning. Emphasis: deterministic wiring to preprocessing artifacts, strict data integrity (fail fast in the core simulation path), and modular components that are individually testable.

### Artifacts (bundled with the package)
- `scaler_X.joblib` and `scaler_y.joblib`
    - These are the scalers that we use to scale the input and output data to match the training data for the best_moe_transformer_model.pt model.
- `best_moe_transformer_model.pt`
    - This is our trained forecasting model that we use to make predictions.
    - Inputs to this model are based on the column ordering in `columns_schema.json` as it's outlined in the `model_input_cols` key.
    - Outputs from this model are based on the column ordering in `columns_schema.json` as it's outlined in the `y_cont_cols` and `y_bin_cols` keys.
    - This is all summarized in the `y_cols` key in `columns_schema.json`.
- `ADNI_Variable_Bounds.csv`
    - This is our ground truth for the environment column bounds. It's calculated as 3 STD from the mean of the training data.
- `columns_schema.json`
    - This is our ground truth for the environment column ordering. Never hand edit this file.
- `initial_state_gaussians.joblib` (required for starts)
    - This artifact is generated by the `build_initial_state_gaussians.py` script.
    - It contains the Gaussian mixture model parameters for the initial state sampling.
    - It also contains the power transformer parameters for the initial state sampling data transformation.
    - It also contains the number of samples for each cohort.
    - It also contains the sample columns for each cohort.

### Core Modules
- **artifact_loader.py**: resolves paths and loads scalers/bounds/schema/Gaussians, instantiates the model (loads the prebuilt artifacts shipped with the installed package).
- **scaler_validator.py**: aligns `scaler_X` feature names (drop `months_since_bl`, map aliases to `next_visit_months`), checks duplicates, missing stats, extra/missing features, required delta and continuous outputs.
- **state_validator.py**: enforces categorical one-hots, clips to ADNI bounds, reports detailed bound violations (non-finite/above/below with tolerance).
- **initial_state_sampler.py**: samples cohort-specific Gaussian starts; applies categorical enforcement and bounds; fails loudly on missing cohorts/weights/transformer.
- **reward_calculator.py**: reliable-change reward for configured metric; clips to ±10; neutralizes reward if bounds fail.
- **alpaca_env.py**: orchestration; episode state, action/observation spaces, action constraints, model input assembly/scaling, prediction, uncertainty, reward, termination/truncation.

### Step Lifecycle
1) If already terminated/truncated, return current state.
2) Ensure current state is finite.
3) Validate action shape/binary; enforce constraints (`No Medication` with others, or all-zero) → terminate with -10 on violation.
4) Build model input = current obs + action + `next_visit_months` (time_delta_val), scale intersecting cols via `scaler_X`, validate columns and finiteness.
5) Append to sequence; build causal attention mask; run model (MC-dropout mean if `mc_samples>0`).
6) Sigmoid binaries; inverse-scale continuous outputs with `scaler_y`; enforce categorical one-hot; round remaining binaries; advance `subject_age` by months/12 if present.
7) Bounds check; if violated → terminate, reward=0. Else compute reliable-change reward.
8) Update state, info (`sequence_length`, MC uncertainty), set truncated if `current_step >= max_episode_length`.

### Notes on Lifecycle
- Input and output into the environment are expected to be in unscaled units so we should always be scaling the inputs into the model and unscaling the outputs from the model.
- MC-dropout uncertainty reporting is best-effort; failures in uncertainty summarization do not fail the step.

### Reset Lifecycle
- Sample start via `InitialStateSampler` for the cohort; reset sequence, episode flags, reward/info.

### Invariants / Watchpoints
- Schema: `model_input_cols` includes all obs + actions + `next_visit_months`; no duplicates.
- Scalers: `scaler_X.feature_names_in_` includes all continuous obs + delta, no extras; `scaler_y` includes all continuous outputs; stats lengths match feature counts.
- Actions: `No Medication_active` must exist; mutually exclusive with any other active action; at least one action must be chosen.
- Categoricals: always project to one-hot after sampling/prediction.
- Bounds: any non-finite state or out-of-bounds next state terminates/neutralizes reward; tolerance scales with magnitude.
- Time: only relative delta (`next_visit_months`) is used; `months_since_bl` is deprecated/ignored in scaling.
- Reward: relies on reward metric being z-scaled; clips to ±10; set `reliability_rxx` as needed.

### Autoregressive Sequence
- Model input sequence grows with each step (`_seq_inputs` list)
- Each step appends data in the format `model_input_cols` from `columns_schema.json` (scaled)
- Causal attention mask: upper triangular (prevents future attention)
- Sequence tensor shape: `(1, sequence_length, model_input_dim)`
- Attention mask shape: `(sequence_length, sequence_length)`

### Categorical Group Processing
- Binary outputs in `y_categorical_groups` are enforced as one-hot (winner-takes-all)
- Winner determined by `argmax` of probabilities within group
- Binary outputs NOT in categorical groups are rounded to 0/1
- Applied both during initial state sampling and after model prediction

### Testing Overview
- Integration (`test_alpaca.py`): env wiring, constraints, reward, bounds, MC dropout, truncation, failure paths.
- Unit (`test_env_modules.py`): loader error paths, scaler alignment/validation, state validator enforcement/bounds, sampler sampling/errors, reward calculator edge cases.
- Tests are meant to focus on ensuring the environment is working as expected. We prioritize ensuring the environment is working as expected over ensuring the environment is robust.

### Extension Tips
- When changing schema/features, regenerate preprocessing artifacts (never hand-edit `columns_schema.json`).
- Keep hyperparameters/configs local to modules/scripts for reproducibility.
- Add unit tests beside new modules; prefer clear `ValueError`s on mismatches.
- Adding actions/metrics: ensure bounds exist, schema lists update, scalers regenerate; test constraint/reward behavior explicitly.
